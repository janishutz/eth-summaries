\newsection
\section{Polynomiale Interpolation}
Bei der Interpolation versuchen wir eine Funktion $\tilde{f}$ durch eine Menge an Datenpunkten einer Funktion $f$ zu finden.\\
Die $x_i$ heissen Stützstellen/Knoten, für welche $\tilde{f}(x_i) = y_i$ gelten soll. (Interpolationsbedingung)

$$ 
\begin{bmatrix}
    x_0 & x_1 & \ldots & x_n \\
    y_0 & y_1 & \ldots & y_n    
\end{bmatrix},
\quad x_i, y_i \in \mathbb{R}
$$

Normalerweise stellt $f$ eine echte Messung dar, d.h. macht es Sinn anzunehmen dass $f$ glatt ist.

Die informelle Problemstellung oben lässt sich durch Vektorräume formalisieren:

$f \in \mathcal{V}$, wobei $\mathcal{V}$ ein Vektorraum mit $\dim(\mathcal{V}) = \infty$ ist. \\
Wir suchen d.h. $\tilde{f}$ in einem Unterraum $\mathcal{V}_n$ mit endlicher $\dim(\mathcal{V}_n) = n$.
Sei $B_n = \{b_1,\ldots,b_n\}$ eine Basis für $\mathcal{V}_n$. 
Dann lässt sich der Bezug zwischen $f$ und $\tilde{f} = f_n(x)$ so ausdrücken:

$$f(x) \approx f_n(x) = \sum_{j=1}^n \alpha_j b_j(x)$$

\setcounter{all}{2}
\inlineremark Unterräume $\mathcal{V}_n$ existieren nicht nur für Polynome, wir beschränken uns aber auf $b_j(x) = x^{i-1}$.
Andere Möglichkeiten: $b_j = \cos((j-1)\cos^-1(x))$ \textit{(Chebyshev)} oder $b_j = e^{i2\pi j x}$ \textit{(Trigonometrisch)}

% This could go into a special "maths theory" section

\setcounter{all}{5}
\fancytheorem{Peano} $f$ stetig $\implies \exists p(x)$ welches $f$ in $||\cdot||_\infty$ beliebig gut approximiert.

\setcounter{all}{7}
\fancydef{Raum der Polynome} $\mathcal{P}_k := \{ x \mapsto \sum_{j = 0}^{k} \alpha_j x^j \}$ \inlinedef \textit{(Monom)} $f: x \mapsto x^k$

\fancytheorem{Eigensch. von $\mathcal{P}_k$} $\mathcal{P}_k$ ist ein Vektorraum mit $\dim(\mathcal{P}_k) = k+1$.

\subsection{Monombasis}

\fancytheorem{Eindeutigkeit} $p(x) \in \mathcal(P)_k$ ist durch $k+1$ Punkte $y_i = p(x_i)$ eindeutig bestimmt.

Dieser Satz kann direkt angewendet werden zur Interpolation, in dem man $p(x)$ als Gleichungssystem schreibt.

$$
p_n(x) = \alpha_n x^n + \cdots + \alpha_0 x^0 \quad \iff \quad 
\underbrace{
    \begin{bmatrix}
    1 & x_0 & \cdots & x_0^n \\
    1 & x_1 & \cdots & x_1^n \\
    \vdots  & \vdots & \ddots & \vdots \\
    1 & x_n & \cdots & x_n^n \\
    \end{bmatrix}
}_\text{Vandermonde Matrix}
\begin{bmatrix}
    \alpha_0 \\
    \alpha_1 \\
    \vdots   \\
    \alpha_n
\end{bmatrix}
=
\begin{bmatrix}
    y_0 \\
    y_1 \\
    \vdots \\
    y_n
\end{bmatrix}
$$

Um $\alpha_i$ zu finden ist die Vandermonde Matrix unbrauchbar, da die Matrix schlecht konditioniert ist.

Zur Auswertung von $p(x)$ kann man direkt die Matrix-darstellung nutzen, oder effizienter:

\fancydef{Horner Schema} $p(x) = (x \ldots x ( x (\alpha_n x + \alpha_{n-1}) + \ldots + \alpha_1) + \alpha_0)$

\fhlc{Cyan}{In NumPy} \verb|polyfit| liefert die direkte Auswertung, \verb|polyval| wertet Polynome via Horner-Schema aus.

\subsection{Newton Basis}

\subsection{Baryzentrische Formel}

\subsection{Chebychev Interpolation}

Lecture: Orthogonalität ist eine wichtige Eigenschaft: Siehe Lecture notes (handgeschr.) für Veranschaulichung. \\
$\rightarrow$ Orth. liefert die Koeff. ohne Rechenaufwand.

Lecture: Clenshaw-Alg. relativ zentral (Taschenrechner nutzen diesen intern)